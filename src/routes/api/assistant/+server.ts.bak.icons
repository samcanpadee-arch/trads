/* Assistant Hybrid RAG:
   - Answers from general knowledge.
   - If uploaded docs are relevant, enrich answer and cite them [1], [2].
   - Node runtime (pdf-parse) + robust Responses handling.
*/
import type { RequestHandler } from "@sveltejs/kit";
import { env as privateEnv } from "$env/dynamic/private";

export const config = {
  runtime: 'nodejs20.x'
};

const CHUNK_SIZE = 500;
const CHUNK_OVERLAP = 80;

function chunkTextWithPages(text: string, pageFrom: number, pageTo: number) {
  const chunks: Array<{ text: string; page_from: number; page_to: number }> = [];
  let i = 0;
  while (i < text.length) {
    const end = Math.min(text.length, i + CHUNK_SIZE);
    const part = text.slice(i, end);
    chunks.push({ text: part, page_from: pageFrom, page_to: pageTo });
    i += Math.max(1, CHUNK_SIZE - CHUNK_OVERLAP);
  }
  if (chunks.length === 0 && text.trim()) {
    chunks.push({ text, page_from: pageFrom, page_to: pageTo });
  }
  return chunks;
}

function cosineSim(a: number[], b: number[]): number {
  let dot = 0, na = 0, nb = 0;
  const n = Math.min(a.length, b.length);
  for (let i = 0; i < n; i++) {
    dot += a[i] * b[i];
    na += a[i] * a[i];
    nb += b[i] * b[i];
  }
  const denom = Math.sqrt(na) * Math.sqrt(nb);
  return denom ? dot / denom : 0;
}

async function embedTexts(texts: string[], apiKey: string) {
  const resp = await fetch("https://api.openai.com/v1/embeddings", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${apiKey}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      model: "text-embedding-3-small",
      input: texts
    })
  });
  if (!resp.ok) {
    const msg = await resp.text();
    throw new Error(`Embeddings failed: ${msg}`);
  }
  const json = await resp.json();
  return json.data.map((d: any) => d.embedding as number[]);
}

async function parsePdf(buffer: Uint8Array) {
  // @ts-expect-error types not bundled
  const pdfParse = (await import("pdf-parse")).default;
  const data = await pdfParse(Buffer.from(buffer), { pagerender: undefined });
  const raw = data.text || "";
  const byPage = raw.split(/\f+|\n\s*Page\s+\d+\s*(?:of\s+\d+)?\s*\n/gi).filter(Boolean);
  return byPage.length ? byPage : [raw];
}

async function fileToText(file: File): Promise<{ name: string; parts: Array<{ text: string; page_from: number; page_to: number }> }> {
  const name = file.name || "upload";
  const type = file.type || "";
  const buf = new Uint8Array(await file.arrayBuffer());

  try {
    if (type === "application/pdf" || name.toLowerCase().endsWith(".pdf")) {
      const pages = await parsePdf(buf);
      let parts: Array<{ text: string; page_from: number; page_to: number }> = [];
      pages.forEach((p, idx) => {
        const pageNum = idx + 1;
        parts = parts.concat(chunkTextWithPages(p, pageNum, pageNum));
      });
      return { name, parts };
    }

    if (type.startsWith("text/") || name.toLowerCase().endsWith(".txt") || name.toLowerCase().endsWith(".md")) {
      const text = new TextDecoder().decode(buf);
      return { name, parts: chunkTextWithPages(text, 1, 1) };
    }
  } catch (e: any) {
    console.error("fileToText error for", name, e);
  }

  return { name, parts: [] };
}

function extractTextFromResponses(resJson: any): string {
  if (!resJson) return "";
  if (typeof resJson.output_text === "string" && resJson.output_text.trim()) {
    return resJson.output_text;
  }
  if (Array.isArray(resJson.output)) {
    const texts: string[] = [];
    for (const item of resJson.output) {
      const parts = item?.content || item?.contents || [];
      for (const p of parts) {
        if (p?.type === "output_text" && typeof p?.text === "string") texts.push(p.text);
        if (p?.type === "text" && typeof p?.text === "string") texts.push(p.text);
      }
    }
    if (texts.length) return texts.join("\n");
  }
  if (Array.isArray(resJson.content)) {
    const first = resJson.content.find((c: any) => typeof c?.text === "string");
    if (first?.text) return first.text;
  }
  return "";
}

export const POST: RequestHandler = async ({ request }) => {
  try {
    if (!privateEnv.OPENAI_API_KEY) {
      return new Response("Missing OPENAI_API_KEY", { status: 500 });
    }

    const ctype = request.headers.get("content-type") || "";
    if (!ctype.includes("multipart/form-data")) {
      return new Response("Send multipart/form-data with fields: message, (optional) trade, brand, model, and files[]", { status: 400 });
    }

    const form = await request.formData();
    const message = (form.get("message") as string || "").trim();
    const trade = (form.get("trade") as string || "").trim();
    const brand = (form.get("brand") as string || "").trim();
    const model = (form.get("model") as string || "").trim();
    if (!message) {
      return new Response("Please include a question in 'message'.", { status: 400 });
    }

    const files = form.getAll("files").filter((f) => f instanceof File) as File[];
    const allParts: Array<{ doc: string; text: string; page_from: number; page_to: number }> = [];
    for (const f of files) {
      const { name, parts } = await fileToText(f);
      for (const p of parts) {
        if (p.text && p.text.trim()) {
          allParts.push({ doc: name, text: p.text, page_from: p.page_from, page_to: p.page_to });
        }
      }
    }

    const MAX_PARTS = 120;
    const partsLimited = allParts.slice(0, MAX_PARTS);

    // Embeddings (keep even low-score matches to allow enrichment)
    let partEmbeddings: number[][] = [];
    let queryEmbedding: number[] = [];
    try {
      if (partsLimited.length > 0) {
        partEmbeddings = await embedTexts(partsLimited.map((p) => p.text), privateEnv.OPENAI_API_KEY);
      }
      const q = [message, trade && `Trade: ${trade}`, brand && `Brand: ${brand}`, model && `Model: ${model}`]
        .filter(Boolean).join("\n");
      queryEmbedding = (await embedTexts([q], privateEnv.OPENAI_API_KEY))[0];
    } catch (e: any) {
      console.error("Embedding error", e);
      return new Response(`Embedding error: ${e?.message || e}`, { status: 500 });
    }

    const scored = partsLimited.map((p, i) => ({
      idx: i,
      score: partEmbeddings[i] ? cosineSim(queryEmbedding, partEmbeddings[i]) : -1,
      ...p
    })).sort((a, b) => b.score - a.score);

    const TOP_K = 15;
    const top = scored.slice(0, TOP_K);

    // Build optional context (only if we have uploads)
    const contextBlocks = top.map((s, i) => {
      const id = i + 1;
      const page = s.page_from === s.page_to ? `p.${s.page_from}` : `p.${s.page_from}-${s.page_to}`;
      const head = `[${id}] ${s.doc} ${page}`;
      return `${head}\n${s.text}`;
    });

    // ðŸ” HYBRID: Use general knowledge, enrich with context when helpful, cite when used
    const SYSTEM = `You are a technical assistant for experienced Australian tradies. Provide detailed, technical answers. Use uploaded manuals FIRST whenever context is relevant, and always cite page numbers (e.g., [p12]) from the provided context. If no relevant context is found, clearly state: "No relevant manual context retrieved â€” using general knowledge." Do not oversimplify; answers should assume professional trade knowledge.`;

    const USER = [
      trade ? `Trade: ${trade}` : null,
      brand ? `Brand: ${brand}` : null,
      model ? `Model: ${model}` : null,
      `Question: ${message}`
    ].filter(Boolean).join("\n");

    const FINAL_PROMPT = [
    contextBlocks.length > 0
      ? "Context blocks (numbered, with page refs):\n" + contextBlocks.join("\n\n")
      : null,
    "Task: Answer in technical detail, in AU English. If context blocks exist, you MUST use them, cite pages inline (e.g., [p12]), and finish with a short checklist. If none exist, explicitly say so before answering with general knowledge."
  ].filter(Boolean).join("\n\n");

    const combined = `${SYSTEM}\n\n---\n\n${USER}\n\n---\n\n${FINAL_PROMPT}`;

    let text = "";
    try {
      const resp = await fetch("https://api.openai.com/v1/responses", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${privateEnv.OPENAI_API_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model: "gpt-4.1-mini",
          input: combined,
          temperature: 0.2
          // No text.format -> plain text
        })
      });

      if (!resp.ok) {
        const msg = await resp.text();
        console.error("OpenAI Responses error", msg);
        return new Response(`OpenAI error: ${msg}`, { status: 500 });
      }

      const data = await resp.json();
      text = extractTextFromResponses(data);
      if (!text || !text.trim()) {
        text = "Sorry â€” I couldn't produce an answer. Try rephrasing the question, or attach a relevant manual/section for more specific guidance.";
      }
    } catch (e: any) {
      console.error("Responses API error", e);
      return new Response(`Responses API error: ${e?.message || e}`, { status: 500 });
    }

    return new Response(text, { status: 200, headers: { "Content-Type": "text/plain; charset=utf-8" } });
  } catch (outer: any) {
    console.error("Unhandled /api/assistant error", outer);
    return new Response(`Internal error: ${outer?.message || outer}`, { status: 500 });
  }
};
